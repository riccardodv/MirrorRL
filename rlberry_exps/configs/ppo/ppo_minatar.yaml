agent_class: 'rlberry.agents.torch.PPOAgent'
init_kwargs:
    learning_rate: 0.00025
    k_epochs: 3
    n_steps: 128
    entr_coef: 0.01
    gae_lambda: 0.95
    batch_size: 32
    eps_clip: 0.1
    vf_coef: 1
    normalize_rewards: False
    optimizer_type: 'ADAM'
    policy_net_fn: 'rlberry.agents.torch.utils.training.model_factory_from_env'
    policy_net_kwargs:
      type: 'MultiLayerPerceptron'
      layer_sizes: [128, 128]
      reshape: False
      is_policy: True
    value_net_fn: 'rlberry.agents.torch.utils.training.model_factory_from_env'
    value_net_kwargs:
      type: "MultiLayerPerceptron"
      layer_sizes: 
        - 128
        - 128
      reshape: False
      out_size: 1
#     entr_coef: 0.01
# eval_kwargs:
#     eval_horizon: 200
n_fit: 1
fit_kwargs:
    fit_budget: 1_000_000
agent_name: "PPO rlberry agent for Acrobot"

